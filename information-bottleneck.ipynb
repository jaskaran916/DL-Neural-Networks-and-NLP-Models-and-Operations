{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Concept of information bottleneck in neural networks by systematically varying the network's capacity**","metadata":{"id":"Pesv5LtCMUXl"}},{"cell_type":"code","source":"# Information Bottleneck Experiment: Varying Network Capacity\n# ==============================================================\n# This script trains simple MLP classifiers on MNIST with varying\n# hidden-layer sizes (network capacity) and estimates mutual\n# information I(X;T) and I(T;Y) for the bottleneck layer via\n# discretization (histogram binning).\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nimport numpy as np\nfrom sklearn.metrics import mutual_info_score\nimport os\n\n# -------------------------\n# Helper: Estimate Mutual Info\n# -------------------------\n\ndef estimate_mutual_info(X, Y, n_bins=30):\n    '''\n    Estimate mutual information between X and Y via histogram binning.\n    X, Y: 1D arrays of same length\n    '''\n    # Digitize\n    bins = np.linspace(np.min(X), np.max(X), n_bins + 1)\n    X_binned = np.digitize(X, bins) - 1\n    Y_binned = np.digitize(Y, bins) - 1 if Y.dtype.kind in 'f' else Y\n\n    # Compute joint histogram\n    return mutual_info_score(X_binned, Y_binned)\n\n# -------------------------\n# MLP with Bottleneck Layer\n# -------------------------\nclass BottleneckMLP(nn.Module):\n    def __init__(self, input_dim, bottleneck_dim, hidden_dim=256, num_classes=10):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.relu = nn.ReLU()\n        self.bottleneck = nn.Linear(hidden_dim, bottleneck_dim)\n        self.fc_out = nn.Linear(bottleneck_dim, num_classes)\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)\n        h = self.relu(self.fc1(x))\n        t = self.relu(self.bottleneck(h))  # bottleneck activations\n        out = self.fc_out(t)\n        return out, t\n\n# -------------------------\n# Training & MI logging\n# -------------------------\n\ndef run_experiment(bottleneck_size, device, epochs=10, batch_size=256):\n    # Data\n    transform = transforms.ToTensor()\n    train_ds = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n    test_ds = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n\n    # Model, opt, loss\n    model = BottleneckMLP(28*28, bottleneck_size).to(device)\n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n    criterion = nn.CrossEntropyLoss()\n\n    # Containers for MI estimates\n    mi_x_t = []  # I(X;T)\n    mi_t_y = []  # I(T;Y)\n\n    for epoch in range(1, epochs+1):\n        model.train()\n        for imgs, labels in train_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            logits, t = model(imgs)\n            loss = criterion(logits, labels)\n            loss.backward()\n            optimizer.step()\n\n        # After epoch: estimate MI on a subset\n        model.eval()\n        all_t = []\n        all_x = []  # flattened inputs\n        all_y = []\n        with torch.no_grad():\n            for imgs, labels in test_loader:\n                imgs, labels = imgs.to(device), labels.to(device)\n                logits, t = model(imgs)\n                all_t.append(t.cpu().numpy())\n                all_x.append(imgs.view(imgs.size(0), -1).cpu().numpy())\n                all_y.append(labels.cpu().numpy())\n        all_t = np.concatenate(all_t, axis=0)\n        all_x = np.concatenate(all_x, axis=0)\n        all_y = np.concatenate(all_y, axis=0)\n\n        # Flatten for MI per neuron then average\n        i_x_t = np.mean([estimate_mutual_info(all_x[:, i], all_t[:, i])\n                           for i in range(min(all_t.shape[1], 50))])\n        i_t_y = np.mean([estimate_mutual_info(all_t[:, i], all_y)\n                           for i in range(min(all_t.shape[1], 50))])\n        mi_x_t.append(i_x_t)\n        mi_t_y.append(i_t_y)\n        print(f\"Bottleneck {bottleneck_size} | Epoch {epoch}: I(X;T)={i_x_t:.4f}, I(T;Y)={i_t_y:.4f}\")\n\n    return mi_x_t, mi_t_y\n\n# -------------------------\n# Main: Sweep over capacities\n# -------------------------\nif __name__ == '__main__':\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    bottleneck_sizes = [5, 10, 20, 50, 100]\n    results = {}\n\n    for size in bottleneck_sizes:\n        print(f\"Running experiment for bottleneck size = {size}\")\n        mi_x_t, mi_t_y = run_experiment(size, device)\n        results[size] = {'I(X;T)': mi_x_t, 'I(T;Y)': mi_t_y}\n\n    # Save results for plotting\n    os.makedirs('results', exist_ok=True)\n    torch.save(results, 'results/ib_results.pth')\n    print(\"All experiments completed. Results saved to results/ib_results.pth\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y99JthtVJ6mI","outputId":"d046c599-3940-4ddb-b675-2af13701f4f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running experiment for bottleneck size = 5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 42.5MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 1.19MB/s]\n","100%|██████████| 1.65M/1.65M [00:00<00:00, 10.8MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 5.35MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Bottleneck 5 | Epoch 1: I(X;T)=0.0000, I(T;Y)=0.5872\n","Bottleneck 5 | Epoch 2: I(X;T)=0.0000, I(T;Y)=0.6147\n","Bottleneck 5 | Epoch 3: I(X;T)=0.0000, I(T;Y)=0.6157\n","Bottleneck 5 | Epoch 4: I(X;T)=0.0000, I(T;Y)=0.6115\n","Bottleneck 5 | Epoch 5: I(X;T)=0.0000, I(T;Y)=0.6069\n","Bottleneck 5 | Epoch 6: I(X;T)=0.0000, I(T;Y)=0.6130\n","Bottleneck 5 | Epoch 7: I(X;T)=0.0000, I(T;Y)=0.6117\n","Bottleneck 5 | Epoch 8: I(X;T)=0.0000, I(T;Y)=0.6135\n","Bottleneck 5 | Epoch 9: I(X;T)=0.0000, I(T;Y)=0.6184\n","Bottleneck 5 | Epoch 10: I(X;T)=0.0000, I(T;Y)=0.6164\n","Running experiment for bottleneck size = 10\n","Bottleneck 10 | Epoch 1: I(X;T)=0.0000, I(T;Y)=0.4868\n","Bottleneck 10 | Epoch 2: I(X;T)=0.0000, I(T;Y)=0.4944\n","Bottleneck 10 | Epoch 3: I(X;T)=0.0000, I(T;Y)=0.5020\n","Bottleneck 10 | Epoch 4: I(X;T)=0.0000, I(T;Y)=0.5133\n","Bottleneck 10 | Epoch 5: I(X;T)=0.0000, I(T;Y)=0.5160\n","Bottleneck 10 | Epoch 6: I(X;T)=0.0000, I(T;Y)=0.5279\n","Bottleneck 10 | Epoch 7: I(X;T)=0.0000, I(T;Y)=0.5292\n","Bottleneck 10 | Epoch 8: I(X;T)=0.0000, I(T;Y)=0.5383\n","Bottleneck 10 | Epoch 9: I(X;T)=0.0000, I(T;Y)=0.5371\n","Bottleneck 10 | Epoch 10: I(X;T)=0.0000, I(T;Y)=0.5373\n","Running experiment for bottleneck size = 20\n","Bottleneck 20 | Epoch 1: I(X;T)=0.0000, I(T;Y)=0.4787\n","Bottleneck 20 | Epoch 2: I(X;T)=0.0000, I(T;Y)=0.4828\n","Bottleneck 20 | Epoch 3: I(X;T)=0.0000, I(T;Y)=0.4980\n","Bottleneck 20 | Epoch 4: I(X;T)=0.0000, I(T;Y)=0.5099\n","Bottleneck 20 | Epoch 5: I(X;T)=0.0000, I(T;Y)=0.5111\n","Bottleneck 20 | Epoch 6: I(X;T)=0.0000, I(T;Y)=0.5190\n","Bottleneck 20 | Epoch 7: I(X;T)=0.0000, I(T;Y)=0.5166\n","Bottleneck 20 | Epoch 8: I(X;T)=0.0000, I(T;Y)=0.5192\n","Bottleneck 20 | Epoch 9: I(X;T)=0.0000, I(T;Y)=0.5193\n","Bottleneck 20 | Epoch 10: I(X;T)=0.0000, I(T;Y)=0.5239\n","Running experiment for bottleneck size = 50\n","Bottleneck 50 | Epoch 1: I(X;T)=0.0003, I(T;Y)=0.4839\n","Bottleneck 50 | Epoch 2: I(X;T)=0.0003, I(T;Y)=0.4956\n","Bottleneck 50 | Epoch 3: I(X;T)=0.0003, I(T;Y)=0.5032\n","Bottleneck 50 | Epoch 4: I(X;T)=0.0003, I(T;Y)=0.5060\n","Bottleneck 50 | Epoch 5: I(X;T)=0.0004, I(T;Y)=0.5176\n","Bottleneck 50 | Epoch 6: I(X;T)=0.0003, I(T;Y)=0.5162\n","Bottleneck 50 | Epoch 7: I(X;T)=0.0003, I(T;Y)=0.5159\n","Bottleneck 50 | Epoch 8: I(X;T)=0.0003, I(T;Y)=0.5229\n","Bottleneck 50 | Epoch 9: I(X;T)=0.0004, I(T;Y)=0.5222\n","Bottleneck 50 | Epoch 10: I(X;T)=0.0004, I(T;Y)=0.5226\n","Running experiment for bottleneck size = 100\n","Bottleneck 100 | Epoch 1: I(X;T)=0.0003, I(T;Y)=0.4635\n","Bottleneck 100 | Epoch 2: I(X;T)=0.0003, I(T;Y)=0.4899\n","Bottleneck 100 | Epoch 3: I(X;T)=0.0003, I(T;Y)=0.4950\n","Bottleneck 100 | Epoch 4: I(X;T)=0.0003, I(T;Y)=0.5049\n","Bottleneck 100 | Epoch 5: I(X;T)=0.0002, I(T;Y)=0.5065\n","Bottleneck 100 | Epoch 6: I(X;T)=0.0003, I(T;Y)=0.5099\n","Bottleneck 100 | Epoch 7: I(X;T)=0.0002, I(T;Y)=0.5112\n","Bottleneck 100 | Epoch 8: I(X;T)=0.0003, I(T;Y)=0.5131\n","Bottleneck 100 | Epoch 9: I(X;T)=0.0003, I(T;Y)=0.5113\n","Bottleneck 100 | Epoch 10: I(X;T)=0.0003, I(T;Y)=0.5057\n","All experiments completed. Results saved to results/ib_results.pth\n"]}],"execution_count":1}]}